Function profiling
==================
  Message: /home/t-najia/workspace/lmkit/original/rnnlm.py:90
  Time in 20 calls to Function.__call__: 1.116093e+01s
  Time in Function.fn.__call__: 1.115843e+01s (99.978%)
  Time in thunks: 1.115193e+01s (99.919%)
  Total compile time: 4.347598e+01s
    Number of Apply nodes: 268
    Theano Optimizer time: 6.663513e+00s
       Theano validate time: 4.909146e-01s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.670606e+01s
       Import time 2.796388e-02s
       Node make_thunk time 3.667810e+01s
           Node forall_inplace,cpu,grad_of_scan_fn}(Elemwise{minimum,no_inplace}.0, InplaceGpuDimShuffle{0,2,1}.0, InplaceGpuDimShuffle{0,1,x}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{::int64}.0, Elemwise{minimum,no_inplace}.0, Elemwise{minimum,no_inplace}.0, Elemwise{minimum,no_inplace}.0, U, Ux, InplaceGpuDimShuffle{1,0}.0, InplaceGpuDimShuffle{1,0}.0) time 1.213342e+01s
           Node GpuIncSubtensor{InplaceSet;:int64:}(GpuAllocEmpty{dtype='float32', context_name=None}.0, Rebroadcast{0}.0, Constant{1}) time 1.909242e+00s
           Node GpuElemwise{Composite{Switch(i0, (i1 * i2), (i3 * i1))}}[]<gpuarray>(InplaceGpuDimShuffle{x,x,x}.0, GpuSubtensor{int64:int64:int8}.0, GpuElemwise{Composite{Cast{float32}(LT(i0, i1))}}[(0, 0)]<gpuarray>.0, GpuArrayConstant{[[[ 0.89999998]]]}) time 1.891546e+00s
           Node GpuElemwise{Add}[(0, 0)]<gpuarray>(GpuReshape{3}.0, InplaceGpuDimShuffle{x,x,0}.0) time 1.889882e+00s
           Node GpuElemwise{Composite{Switch(i0, (i1 * i2), (i3 * i2))}}[(0, 1)]<gpuarray>(InplaceGpuDimShuffle{x,x,x}.0, GpuElemwise{Composite{Cast{float32}(LT(i0, i1))}}[(0, 0)]<gpuarray>.0, GpuReshape{3}.0, GpuArrayConstant{[[[ 0.89999998]]]}) time 1.887892e+00s

Time in all call to theano.grad() 6.318433e-01s
Time since theano import 62.449s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  48.9%    48.9%       5.459s       2.48e-02s     C      220      11   theano.gpuarray.blas.GpuDot22
  22.4%    71.4%       2.500s       6.25e-02s     Py      40       2   theano.scan_module.scan_op.Scan
   8.0%    79.4%       0.894s       9.51e-04s     C      940      47   theano.gpuarray.elemwise.GpuElemwise
   7.5%    86.9%       0.834s       4.17e-02s     C       20       1   theano.gpuarray.nnet.GpuCrossentropySoftmaxArgmax1HotWithBias
   4.7%    91.5%       0.523s       1.63e-03s     C      320      16   theano.gpuarray.basic_ops.GpuReshape
   2.9%    94.4%       0.322s       3.22e-03s     C      100       5   theano.gpuarray.elemwise.GpuCAReduceCuda
   2.8%    97.3%       0.317s       1.58e-02s     C       20       1   theano.gpuarray.nnet.GpuCrossentropySoftmax1HotWithBiasDx
   2.4%    99.6%       0.264s       1.32e-02s     C       20       1   theano.gpuarray.subtensor.GpuAdvancedSubtensor1
   0.2%    99.9%       0.026s       2.64e-04s     C      100       5   theano.gpuarray.basic_ops.GpuAlloc
   0.0%    99.9%       0.005s       4.39e-05s     C      120       6   theano.gpuarray.subtensor.GpuIncSubtensor
   0.0%    99.9%       0.002s       5.04e-05s     C       40       2   theano.gpuarray.subtensor.GpuAdvancedIncSubtensor1_dev20
   0.0%   100.0%       0.002s       1.00e-06s     C     1880      94   theano.tensor.elemwise.Elemwise
   0.0%   100.0%       0.002s       1.27e-05s     C      120       6   theano.gpuarray.basic_ops.GpuFromHost
   0.0%   100.0%       0.001s       4.19e-05s     C       20       1   theano.sandbox.rng_mrg.GPUA_mrg_uniform
   0.0%   100.0%       0.001s       2.26e-06s     C      340      17   theano.gpuarray.elemwise.GpuDimShuffle
   0.0%   100.0%       0.000s       2.17e-06s     C      220      11   theano.gpuarray.subtensor.GpuSubtensor
   0.0%   100.0%       0.000s       1.67e-05s     C       20       1   theano.gpuarray.basic_ops.HostFromGpu
   0.0%   100.0%       0.000s       9.85e-07s     C      260      13   theano.compile.ops.Shape_i
   0.0%   100.0%       0.000s       1.15e-06s     C      200      10   theano.tensor.opt.MakeVector
   0.0%   100.0%       0.000s       5.39e-07s     C      260      13   theano.tensor.basic.ScalarFromTensor
   ... (remaining 4 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  48.9%    48.9%       5.459s       2.48e-02s     C      220       11   GpuDot22
  17.0%    65.9%       1.895s       9.48e-02s     Py      20        1   forall_inplace,cpu,grad_of_scan_fn}
   7.5%    73.4%       0.834s       4.17e-02s     C       20        1   GpuCrossentropySoftmaxArgmax1HotWithBias
   5.4%    78.8%       0.604s       3.02e-02s     Py      20        1   forall_inplace,cpu,scan_fn}
   4.7%    83.5%       0.522s       2.61e-03s     C      200       10   GpuReshape{2}
   2.8%    86.4%       0.317s       1.59e-02s     C       20        1   GpuCAReduceCuda{add}{0}
   2.8%    89.2%       0.317s       1.58e-02s     C       20        1   GpuCrossentropySoftmax1HotWithBiasDx
   2.5%    91.7%       0.278s       1.54e-03s     C      180        9   GpuElemwise{Composite{(i0 - ((i1 * i2) / (i3 + sqrt(i4))))}}[(0, 0)]<gpuarray>
   2.4%    94.1%       0.264s       1.32e-02s     C       20        1   GpuAdvancedSubtensor1
   1.9%    96.0%       0.212s       1.18e-03s     C      180        9   GpuElemwise{Composite{((i0 * i1) + (i2 * sqr(i3)))}}[(0, 1)]<gpuarray>
   1.9%    97.9%       0.211s       1.17e-03s     C      180        9   GpuElemwise{Composite{((i0 * i1) + (i2 * i3))}}[(0, 1)]<gpuarray>
   1.7%    99.5%       0.187s       1.04e-03s     C      180        9   GpuElemwise{Clip}[(0, 0)]<gpuarray>
   0.2%    99.8%       0.026s       2.64e-04s     C      100        5   GpuAlloc<None>{memset_0=True}
   0.0%    99.8%       0.004s       9.42e-05s     C       40        2   GpuCAReduceCuda{add}{0, 1}
   0.0%    99.8%       0.003s       7.15e-05s     C       40        2   GpuIncSubtensor{Inc;:int64:}
   0.0%    99.9%       0.002s       5.04e-05s     C       40        2   GpuAdvancedIncSubtensor1_dev20{inplace=True, set_instead_of_inc=False}
   0.0%    99.9%       0.002s       3.35e-05s     C       60        3   GpuIncSubtensor{InplaceInc;int64::}
   0.0%    99.9%       0.002s       1.27e-05s     C      120        6   GpuFromHost<None>
   0.0%    99.9%       0.001s       3.48e-05s     C       40        2   GpuElemwise{Add}[(0, 0)]<gpuarray>
   0.0%    99.9%       0.001s       4.25e-05s     C       20        1   GpuElemwise{Composite{Switch(i0, (i1 * i2), (i3 * i2))}}[(0, 1)]<gpuarray>
   ... (remaining 70 Ops account for   0.09%(0.01s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  31.4%    31.4%       3.498s       1.75e-01s     20   196   GpuDot22(GpuCrossentropySoftmax1HotWithBiasDx.0, InplaceGpuDimShuffle{1,0}.0)
  17.0%    48.4%       1.895s       9.48e-02s     20   210   forall_inplace,cpu,grad_of_scan_fn}(Elemwise{minimum,no_inplace}.0, InplaceGpuDimShuffle{0,2,1}.0, InplaceGpuDimShuffle{0,1,x}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{::int64}.0, Elemwise{minimum,no_inplace}.0, Elemwise{minimum,no_inplace}.0, Elemwise{minimum,no_inplace}.0, U, Ux, InplaceGpuDimShuffle{1,0}.0, InplaceGpuDimShuffle{1,0}.0)
   9.7%    58.0%       1.077s       5.39e-02s     20   181   GpuDot22(GpuReshape{2}.0, output_W)
   7.7%    65.7%       0.853s       4.27e-02s     20   195   GpuDot22(InplaceGpuDimShuffle{1,0}.0, GpuCrossentropySoftmax1HotWithBiasDx.0)
   7.5%    73.2%       0.834s       4.17e-02s     20   184   GpuCrossentropySoftmaxArgmax1HotWithBias(GpuDot22.0, output_b, GpuReshape{1}.0)
   5.4%    78.6%       0.604s       3.02e-02s     20   167   forall_inplace,cpu,scan_fn}(Elemwise{minimum,no_inplace}.0, InplaceGpuDimShuffle{0,1,x}.0, GpuSubtensor{int64:int64:int8}.0, GpuSubtensor{int64:int64:int8}.0, GpuIncSubtensor{InplaceSet;:int64:}.0, U, Ux)
   4.7%    83.3%       0.522s       2.61e-02s     20   191   GpuReshape{2}(InplaceGpuDimShuffle{2,0,1}.0, TensorConstant{[256  -1]})
   2.8%    86.1%       0.317s       1.59e-02s     20   194   GpuCAReduceCuda{add}{0}(GpuCrossentropySoftmax1HotWithBiasDx.0)
   2.8%    88.9%       0.317s       1.58e-02s     20   192   GpuCrossentropySoftmax1HotWithBiasDx(GpuElemwise{TrueDiv}[(0, 0)]<gpuarray>.0, GpuCrossentropySoftmaxArgmax1HotWithBias.1, GpuReshape{1}.0)
   2.4%    91.3%       0.264s       1.32e-02s     20    66   GpuAdvancedSubtensor1(word_embedding, GpuContiguous.0)
   1.3%    92.6%       0.141s       7.04e-03s     20   267   GpuElemwise{Composite{(i0 - ((i1 * i2) / (i3 + sqrt(i4))))}}[(0, 0)]<gpuarray>(word_embedding, InplaceGpuDimShuffle{x,x}.0, GpuElemwise{Composite{((i0 * i1) + (i2 * i3))}}[(0, 1)]<gpuarray>.0, GpuArrayConstant{[[  9.99999994e-09]]}, GpuElemwise{Composite{((i0 * i1) + (i2 * sqr(i3)))}}[(0, 1)]<gpuarray>.0)
   1.2%    93.8%       0.134s       6.69e-03s     20   207   GpuElemwise{Composite{(i0 - ((i1 * i2) / (i3 + sqrt(i4))))}}[(0, 0)]<gpuarray>(output_W, InplaceGpuDimShuffle{x,x}.0, GpuElemwise{Composite{((i0 * i1) + (i2 * i3))}}[(0, 1)]<gpuarray>.0, GpuArrayConstant{[[  9.99999994e-09]]}, GpuElemwise{Composite{((i0 * i1) + (i2 * sqr(i3)))}}[(0, 1)]<gpuarray>.0)
   0.9%    94.7%       0.105s       5.23e-03s     20   203   GpuElemwise{Composite{((i0 * i1) + (i2 * sqr(i3)))}}[(0, 1)]<gpuarray>(GpuArrayConstant{[[ 0.99900001]]}, <GpuArrayType<None>(float32, (False, False))>, GpuArrayConstant{[[ 0.00099999]]}, GpuElemwise{Clip}[(0, 0)]<gpuarray>.0)
   0.9%    95.6%       0.104s       5.22e-03s     20   265   GpuElemwise{Composite{((i0 * i1) + (i2 * sqr(i3)))}}[(0, 1)]<gpuarray>(GpuArrayConstant{[[ 0.99900001]]}, <GpuArrayType<None>(float32, (False, False))>, GpuArrayConstant{[[ 0.00099999]]}, GpuElemwise{Clip}[(0, 0)]<gpuarray>.0)
   0.9%    96.6%       0.104s       5.19e-03s     20   204   GpuElemwise{Composite{((i0 * i1) + (i2 * i3))}}[(0, 1)]<gpuarray>(GpuArrayConstant{[[ 0.89999998]]}, <GpuArrayType<None>(float32, (False, False))>, GpuArrayConstant{[[ 0.10000002]]}, GpuElemwise{Clip}[(0, 0)]<gpuarray>.0)
   0.9%    97.5%       0.104s       5.18e-03s     20   266   GpuElemwise{Composite{((i0 * i1) + (i2 * i3))}}[(0, 1)]<gpuarray>(GpuArrayConstant{[[ 0.89999998]]}, <GpuArrayType<None>(float32, (False, False))>, GpuArrayConstant{[[ 0.10000002]]}, GpuElemwise{Clip}[(0, 0)]<gpuarray>.0)
   0.8%    98.3%       0.093s       4.64e-03s     20   199   GpuElemwise{Clip}[(0, 0)]<gpuarray>(GpuDot22.0, GpuArrayConstant{[[-10]]}, GpuArrayConstant{[[10]]})
   0.8%    99.2%       0.091s       4.55e-03s     20   264   GpuElemwise{Clip}[(0, 0)]<gpuarray>(GpuAdvancedIncSubtensor1_dev20{inplace=True, set_instead_of_inc=False}.0, GpuArrayConstant{[[-10]]}, GpuArrayConstant{[[10]]})
   0.2%    99.4%       0.024s       1.19e-03s     20    40   GpuAlloc<None>{memset_0=True}(GpuArrayConstant{[[ 0.]]}, Shape_i{0}.0, Shape_i{1}.0)
   0.0%    99.4%       0.005s       2.57e-04s     20   235   GpuDot22(GpuReshape{2}.0, InplaceGpuDimShuffle{1,0}.0)
   ... (remaining 248 Apply instances account for 0.59%(0.07s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  - Try installing amdlibm and set the Theano flag lib.amdlibm=True. This speeds up only some Elemwise operation.

Scan Op profiling ( grad_of_scan_fn )
==================
  Message: None
  Time in 20 calls of the op (for a total of 3367 steps) 1.892328e+00s

  Total time spent in calling the VM 1.598573e+00s (84.477%)
  Total overhead (computing slices..) 2.937546e-01s (15.523%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  30.6%    30.6%       0.479s       1.42e-05s     C    33670      10   theano.gpuarray.elemwise.GpuElemwise
  28.0%    58.6%       0.438s       6.51e-05s     C     6734       2   theano.gpuarray.blas.GpuDot22
  26.8%    85.4%       0.420s       6.23e-05s     C     6734       2   theano.gpuarray.blas.GpuGemm
  10.2%    95.5%       0.159s       2.37e-05s     C     6734       2   theano.gpuarray.subtensor.GpuIncSubtensor
   3.4%    99.0%       0.054s       1.60e-05s     C     3367       1   theano.gpuarray.basic_ops.GpuAlloc
   0.9%    99.9%       0.014s       2.14e-06s     C     6734       2   theano.gpuarray.subtensor.GpuSubtensor
   0.1%   100.0%       0.001s       2.10e-07s     C     6734       2   theano.compile.ops.Shape_i
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  28.0%    28.0%       0.438s       6.51e-05s     C     6734        2   GpuDot22
  15.0%    43.0%       0.235s       6.99e-05s     C     3367        1   GpuGemm{inplace=False}
  11.8%    54.8%       0.184s       5.47e-05s     C     3367        1   GpuGemm{inplace=True}
   6.9%    61.6%       0.107s       3.19e-05s     C     3367        1   GpuIncSubtensor{Inc;::, int64:int64:}
   6.1%    67.7%       0.096s       1.42e-05s     C     6734        2   GpuElemwise{mul}[]<gpuarray>
   3.4%    71.2%       0.054s       1.60e-05s     C     3367        1   GpuAlloc<None>{memset_0=True}
   3.3%    74.5%       0.052s       1.56e-05s     C     3367        1   Gpusigmoid
   3.3%    77.8%       0.052s       1.55e-05s     C     3367        1   GpuIncSubtensor{InplaceInc;::, int64:int64:}
   3.2%    81.1%       0.051s       1.50e-05s     C     3367        1   GpuElemwise{ScalarSigmoid}[(0, 0)]<gpuarray>
   3.2%    84.2%       0.050s       1.47e-05s     C     3367        1   GpuElemwise{Composite{tanh(((i0 * i1) + i2))}}[]<gpuarray>
   3.0%    87.3%       0.048s       1.41e-05s     C     3367        1   GpuElemwise{Composite{(i0 * i1 * i2 * (i3 - i2))}}[(0, 1)]<gpuarray>
   3.0%    90.2%       0.047s       1.38e-05s     C     3367        1   GpuElemwise{Composite{((i0 * i1) + i2 + i3)}}[(0, 2)]<gpuarray>
   3.0%    93.2%       0.046s       1.38e-05s     C     3367        1   GpuElemwise{Composite{(i0 * i1 * (i2 - sqr(i3)))}}[]<gpuarray>
   2.9%    96.1%       0.046s       1.37e-05s     C     3367        1   GpuElemwise{Composite{(((-(i0 * i1)) + (i0 * i2)) * i3 * i4)}}[(0, 1)]<gpuarray>
   2.9%    99.0%       0.045s       1.33e-05s     C     3367        1   GpuElemwise{sub}[]<gpuarray>
   0.9%    99.9%       0.014s       2.14e-06s     C     6734        2   GpuSubtensor{::, int64:int64:}
   0.1%   100.0%       0.001s       2.48e-07s     C     3367        1   Shape_i{0}
   0.0%   100.0%       0.001s       1.71e-07s     C     3367        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  17.1%    17.1%       0.268s       7.96e-05s   3367    18   GpuDot22(GpuIncSubtensor{Inc;::, int64:int64:}.0, U_copy.T_replace[Gpua])
  15.0%    32.1%       0.235s       6.99e-05s   3367     0   GpuGemm{inplace=False}(<GpuArrayType<None>(float32, (False, False))>, TensorConstant{1.0}, <GpuArrayType<None>(float32, (False, False))>, U_copy[Gpua], TensorConstant{1.0})
  11.8%    43.9%       0.184s       5.47e-05s   3367    19   GpuGemm{inplace=True}(GpuDot22.0, TensorConstant{1.0}, GpuElemwise{mul}[]<gpuarray>.0, Ux_copy.T_replace[Gpua], TensorConstant{1.0})
  10.9%    54.8%       0.170s       5.05e-05s   3367     3   GpuDot22(<GpuArrayType<None>(float32, (False, False))>, Ux_copy[Gpua])
   6.9%    61.6%       0.107s       3.19e-05s   3367    17   GpuIncSubtensor{Inc;::, int64:int64:}(GpuIncSubtensor{InplaceInc;::, int64:int64:}.0, GpuElemwise{Composite{(i0 * i1 * i2 * (i3 - i2))}}[(0, 1)]<gpuarray>.0, Constant{0}, Constant{256})
   3.4%    65.1%       0.054s       1.60e-05s   3367     7   GpuAlloc<None>{memset_0=True}(GpuArrayConstant{[[ 0.]]}, Shape_i{0}.0, Shape_i{1}.0)
   3.3%    68.4%       0.052s       1.56e-05s   3367     8   Gpusigmoid(GpuSubtensor{::, int64:int64:}.0)
   3.3%    71.7%       0.052s       1.55e-05s   3367    16   GpuIncSubtensor{InplaceInc;::, int64:int64:}(GpuAlloc<None>{memset_0=True}.0, GpuElemwise{Composite{(((-(i0 * i1)) + (i0 * i2)) * i3 * i4)}}[(0, 1)]<gpuarray>.0, Constant{256}, Constant{512})
   3.2%    75.0%       0.051s       1.50e-05s   3367     9   GpuElemwise{ScalarSigmoid}[(0, 0)]<gpuarray>(GpuSubtensor{::, int64:int64:}.0)
   3.2%    78.1%       0.050s       1.47e-05s   3367    11   GpuElemwise{Composite{tanh(((i0 * i1) + i2))}}[]<gpuarray>(GpuDot22.0, GpuElemwise{ScalarSigmoid}[(0, 0)]<gpuarray>.0, <GpuArrayType<None>(float32, (False, False))>)
   3.2%    81.3%       0.049s       1.47e-05s   3367     4   GpuElemwise{mul}[]<gpuarray>(<GpuArrayType<None>(float32, (False, False))>, <GpuArrayType<None>(float32, (False, True))>)
   3.0%    84.3%       0.048s       1.41e-05s   3367    15   GpuElemwise{Composite{(i0 * i1 * i2 * (i3 - i2))}}[(0, 1)]<gpuarray>(GpuElemwise{Composite{(i0 * i1 * (i2 - sqr(i3)))}}[]<gpuarray>.0, GpuDot22.0, GpuElemwise{ScalarSigmoid}[(0, 0)]<gpuarray>.0, GpuArrayConstant{[[ 1.]]})
   3.0%    87.3%       0.047s       1.38e-05s   3367    20   GpuElemwise{Composite{((i0 * i1) + i2 + i3)}}[(0, 2)]<gpuarray>(GpuElemwise{mul}[]<gpuarray>.0, Gpusigmoid.0, <GpuArrayType<None>(float32, (False, False))>, GpuGemm{inplace=True}.0)
   3.0%    90.3%       0.046s       1.38e-05s   3367    12   GpuElemwise{Composite{(i0 * i1 * (i2 - sqr(i3)))}}[]<gpuarray>(GpuElemwise{mul}[]<gpuarray>.0, GpuElemwise{sub}[]<gpuarray>.0, GpuArrayConstant{[[ 1.]]}, GpuElemwise{Composite{tanh(((i0 * i1) + i2))}}[]<gpuarray>.0)
   2.9%    93.2%       0.046s       1.37e-05s   3367    14   GpuElemwise{mul}[]<gpuarray>(GpuElemwise{Composite{(i0 * i1 * (i2 - sqr(i3)))}}[]<gpuarray>.0, GpuElemwise{ScalarSigmoid}[(0, 0)]<gpuarray>.0)
   2.9%    96.1%       0.046s       1.37e-05s   3367    13   GpuElemwise{Composite{(((-(i0 * i1)) + (i0 * i2)) * i3 * i4)}}[(0, 1)]<gpuarray>(GpuElemwise{mul}[]<gpuarray>.0, GpuElemwise{Composite{tanh(((i0 * i1) + i2))}}[]<gpuarray>.0, <GpuArrayType<None>(float32, (False, False))>, Gpusigmoid.0, GpuElemwise{sub}[]<gpuarray>.0)
   2.9%    99.0%       0.045s       1.33e-05s   3367    10   GpuElemwise{sub}[]<gpuarray>(GpuArrayConstant{[[ 1.]]}, Gpusigmoid.0)
   0.6%    99.6%       0.009s       2.65e-06s   3367     6   GpuSubtensor{::, int64:int64:}(GpuGemm{inplace=False}.0, Constant{256}, Constant{512})
   0.4%    99.9%       0.006s       1.64e-06s   3367     5   GpuSubtensor{::, int64:int64:}(GpuGemm{inplace=False}.0, Constant{0}, Constant{256})
   0.1%   100.0%       0.001s       2.48e-07s   3367     2   Shape_i{0}(<GpuArrayType<None>(float32, (False, False))>)
   ... (remaining 1 Apply instances account for 0.04%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  - Try installing amdlibm and set the Theano flag lib.amdlibm=True. This speeds up only some Elemwise operation.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 20 calls of the op (for a total of 3367 steps) 6.029754e-01s

  Total time spent in calling the VM 4.974499e-01s (82.499%)
  Total overhead (computing slices..) 1.055255e-01s (17.501%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  50.2%    50.2%       0.244s       7.24e-05s     C     3367       1   theano.gpuarray.blas.GpuGemm
  35.1%    85.3%       0.170s       5.06e-05s     C     3367       1   theano.gpuarray.blas.GpuDot22
  12.0%    97.3%       0.058s       1.73e-05s     C     3367       1   theano.gpuarray.elemwise.GpuElemwise
   2.7%   100.0%       0.013s       1.93e-06s     C     6734       2   theano.gpuarray.subtensor.GpuSubtensor
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  50.2%    50.2%       0.244s       7.24e-05s     C     3367        1   GpuGemm{inplace=False}
  35.1%    85.3%       0.170s       5.06e-05s     C     3367        1   GpuDot22
  12.0%    97.3%       0.058s       1.73e-05s     C     3367        1   GpuElemwise{Composite{((((i0 - scalar_sigmoid(i1)) * tanh(((i2 * scalar_sigmoid(i3)) + i4))) + (scalar_sigmoid(i1) * i5)) * i6)}}[]<gpuarray>
   2.7%   100.0%       0.013s       1.93e-06s     C     6734        2   GpuSubtensor{::, int64:int64:}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  50.2%    50.2%       0.244s       7.24e-05s   3367     0   GpuGemm{inplace=False}(<GpuArrayType<None>(float32, (False, False))>, TensorConstant{1.0}, <GpuArrayType<None>(float32, (False, False))>, U_copy[Gpua], TensorConstant{1.0})
  35.1%    85.3%       0.170s       5.06e-05s   3367     1   GpuDot22(<GpuArrayType<None>(float32, (False, False))>, Ux_copy[Gpua])
  12.0%    97.3%       0.058s       1.73e-05s   3367     4   GpuElemwise{Composite{((((i0 - scalar_sigmoid(i1)) * tanh(((i2 * scalar_sigmoid(i3)) + i4))) + (scalar_sigmoid(i1) * i5)) * i6)}}[]<gpuarray>(GpuArrayConstant{[[ 1.]]}, GpuSubtensor{::, int64:int64:}.0, GpuDot22.0, GpuSubtensor{::, int64:int64:}.0, <GpuArrayType<None>(float32, (False, False))>, <GpuArrayType<None>(float32, (False, False))>, <GpuArrayType<None>(float32, (False, True))>)
   1.6%    99.0%       0.008s       2.36e-06s   3367     3   GpuSubtensor{::, int64:int64:}(GpuGemm{inplace=False}.0, Constant{256}, Constant{512})
   1.0%   100.0%       0.005s       1.50e-06s   3367     2   GpuSubtensor{::, int64:int64:}(GpuGemm{inplace=False}.0, Constant{0}, Constant{256})
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  - Try installing amdlibm and set the Theano flag lib.amdlibm=True. This speeds up only some Elemwise operation.
